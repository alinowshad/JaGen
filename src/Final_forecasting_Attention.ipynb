{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T16:27:06.980190Z","iopub.status.busy":"2023-08-01T16:27:06.978665Z","iopub.status.idle":"2023-08-01T16:28:49.843069Z","shell.execute_reply":"2023-08-01T16:28:49.841727Z","shell.execute_reply.started":"2023-08-01T16:27:06.980137Z"},"trusted":true},"outputs":[],"source":["# installing bayesian optimization \n","!pip install GPy\n","!pip install GPyOpt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:07.084939Z","iopub.status.busy":"2023-08-01T17:31:07.084468Z","iopub.status.idle":"2023-08-01T17:31:07.098968Z","shell.execute_reply":"2023-08-01T17:31:07.097277Z","shell.execute_reply.started":"2023-08-01T17:31:07.084904Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","import tensorflow as tf\n","import keras\n","import keras.backend as K\n","from keras import layers\n","from keras.models import Sequential,Model\n","import keras.layers as kl\n","from keras.layers.merge import concatenate\n","import gc\n","import math\n","import time\n","import GPy, GPyOpt\n","import statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:07.969879Z","iopub.status.busy":"2023-08-01T17:31:07.969452Z","iopub.status.idle":"2023-08-01T17:31:07.980961Z","shell.execute_reply":"2023-08-01T17:31:07.979366Z","shell.execute_reply.started":"2023-08-01T17:31:07.969844Z"},"trusted":true},"outputs":[],"source":["# computing RMSE and SMAPE for single and multiple points\n","def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n","\n","def single_point_smape(actual, forecast):\n","    return (100/len(actual)) * (np.sum(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast))))\n","def smape(actual, forecast):\n","    sum_smape=0\n","    for i in range(len(actual)):\n","        sum_smape+=single_point_smape(actual[i],forecast[i])\n","    return sum_smape/len(actual)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:08.145867Z","iopub.status.busy":"2023-08-01T17:31:08.145447Z","iopub.status.idle":"2023-08-01T17:31:08.155967Z","shell.execute_reply":"2023-08-01T17:31:08.154772Z","shell.execute_reply.started":"2023-08-01T17:31:08.145832Z"},"trusted":true},"outputs":[],"source":["# creating samples from raw time series\n","# look_forward is number of points we want to predict from each sample.\n","# look_back is simply lag size ( window size ). \n","def create_dataset(dataset, look_back,look_forward=7):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-look_back-look_forward+1):\n","        a = dataset[i:(i+look_back), 0]\n","        dataX.append(a)\n","        a=dataset[(i + look_back):(i + look_back+look_forward), 0]\n","        dataY.append(a)\n","    return np.array(dataX), np.array(dataY)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:08.306590Z","iopub.status.busy":"2023-08-01T17:31:08.306081Z","iopub.status.idle":"2023-08-01T17:31:08.316307Z","shell.execute_reply":"2023-08-01T17:31:08.314752Z","shell.execute_reply.started":"2023-08-01T17:31:08.306547Z"},"trusted":true},"outputs":[],"source":["# creating samples based on features \n","def create_dataset_features(dataset, look_back,look_forward=7):\n","    sample = []\n","    sample = [float(item) for item in dataset[look_back-5] if math.isnan(item)==False]\n","    sample=np.array(sample)\n","    sample = sample.reshape(sample.shape[0],1)\n","    # number of features are 11, thus we reshape based on this\n","    sample=sample.reshape(11,int(len(sample)/11))\n","    sample=sample.T\n","    sample=np.array(sample)\n","    sample=sample[0:-look_forward]\n","    return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:08.479792Z","iopub.status.busy":"2023-08-01T17:31:08.479320Z","iopub.status.idle":"2023-08-01T17:31:08.493312Z","shell.execute_reply":"2023-08-01T17:31:08.491560Z","shell.execute_reply.started":"2023-08-01T17:31:08.479756Z"},"trusted":true},"outputs":[],"source":["# here we need to split train, test, validation\n","def train_test_split(dataX,dataY,one_sample,look_back,look_forward):\n","    # test size should be selected manually, here we just select the points not number of samples.\n","    testsize=35\n","    train_size=(len(one_sample)-look_forward)-testsize-look_back+1\n","    \n","    trainX, testX = dataX[0:train_size,:], dataX[train_size+look_forward-1:,:]\n","    trainY, testY = dataY[0:train_size,:], dataY[train_size+look_forward-1:,:]\n","    # validation size should be selected manually, here we just select the points not number of samples.\n","    valsize=33\n","\n","    valX, valY=trainX[train_size-valsize+look_forward-1:train_size,:],trainY[train_size-valsize+look_forward-1:train_size]\n","\n","    trainX = np.reshape(trainX, (trainX.shape[0],1, trainX.shape[1]))\n","    valX= np.reshape(valX, (valX.shape[0],1, valX.shape[1]))\n","    testX = np.reshape(testX, (testX.shape[0],1, testX.shape[1]))\n","    return np.array(trainX),np.array(valX),np.array(testX),np.array(trainY),np.array(valY),np.array(testY)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:08.648211Z","iopub.status.busy":"2023-08-01T17:31:08.647691Z","iopub.status.idle":"2023-08-01T17:31:08.702913Z","shell.execute_reply":"2023-08-01T17:31:08.701295Z","shell.execute_reply.started":"2023-08-01T17:31:08.648171Z"},"trusted":true},"outputs":[],"source":["# reading the corresponding country csv file. this is confirmed cases dataset.\n","all_train = pd.read_csv('/kaggle/input/us-covid19-with-feature/US.csv')\n","all_train=np.array(all_train)\n","all_train = all_train.flatten()\n","all_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:08.853792Z","iopub.status.busy":"2023-08-01T17:31:08.853206Z","iopub.status.idle":"2023-08-01T17:31:08.874496Z","shell.execute_reply":"2023-08-01T17:31:08.873515Z","shell.execute_reply.started":"2023-08-01T17:31:08.853753Z"},"trusted":true},"outputs":[],"source":["# reading the feature file.\n","features = pd.read_csv('/kaggle/input/us-covid19-with-feature/US_features.csv')\n","features=features.T\n","features=np.array(features)\n","features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:09.050746Z","iopub.status.busy":"2023-08-01T17:31:09.049485Z","iopub.status.idle":"2023-08-01T17:31:09.064790Z","shell.execute_reply":"2023-08-01T17:31:09.063264Z","shell.execute_reply.started":"2023-08-01T17:31:09.050682Z"},"trusted":true},"outputs":[],"source":["look_back=0\n","def final_sample_creation(one_sample,features,lag,look_forward,all_features,):\n","    # we should define the look_forward variable. this is the number of points we want to predict.\n","    # our problem is multi-variable prediction and in this dataset the output length is 7. \n","    look_forward=7\n","    look_back=lag\n","\n","    one_sample=np.array(one_sample)\n","    one_sample = one_sample.astype('int64')\n","    one_sample = one_sample.reshape(one_sample.shape[0],1)\n","    \n","\n","    dataX_s, dataY_s = create_dataset(one_sample,look_back,look_forward)\n","    trainX,valX,testX,trainY,valY,testY = train_test_split(dataX_s,dataY_s,one_sample,look_back,look_forward)\n","    \n","    dataX_features = create_dataset_features(features,look_back,look_forward)\n","    dataX_features = dataX_features[:, all_features]\n","    \n","    trainX_f = dataX_features[0:len(trainX)]\n","    valX_f   = dataX_features[len(trainX)-len(valX):len(trainX)]\n","    testX_f  = dataX_features[-len(testX):]\n","    \n","    trainX_f = np.reshape(trainX_f, (trainX_f.shape[0],1, trainX_f.shape[1]))\n","    valX_f= np.reshape(valX_f, (valX_f.shape[0],1, valX_f.shape[1]))\n","    testX_f = np.reshape(testX_f, (testX_f.shape[0],1, testX_f.shape[1]))\n","\n","    return trainX,valX,testX,trainY,valY,testY,trainX_f,valX_f,testX_f"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:09.400229Z","iopub.status.busy":"2023-08-01T17:31:09.399316Z","iopub.status.idle":"2023-08-01T17:31:09.408551Z","shell.execute_reply":"2023-08-01T17:31:09.407318Z","shell.execute_reply.started":"2023-08-01T17:31:09.400179Z"},"trusted":true},"outputs":[],"source":["def HyperParameter_mapping(hyper_parametrs):\n","    \n","    learning_rate = hyper_parametrs[0]\n","    \n","    \n","    if hyper_parametrs[1]==0:\n","        denselayer_activation=None\n","    elif hyper_parametrs[1]==1:\n","        denselayer_activation=\"relu\"\n","    elif hyper_parametrs[1]==2:\n","        denselayer_activation=\"linear\"\n","    \n","    \n","    \n","    if hyper_parametrs[2]==0:\n","        output_activation=None\n","    elif hyper_parametrs[2]==1:\n","        output_activation=\"relu\"\n","    elif hyper_parametrs[2]==2:\n","        output_activation=\"linear\"\n","    \n","    return learning_rate,denselayer_activation,output_activation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:09.803623Z","iopub.status.busy":"2023-08-01T17:31:09.803174Z","iopub.status.idle":"2023-08-01T17:31:09.813078Z","shell.execute_reply":"2023-08-01T17:31:09.811414Z","shell.execute_reply.started":"2023-08-01T17:31:09.803582Z"},"trusted":true},"outputs":[],"source":["# defining hyper parameters and available range to pass it to the bayesian optimization algorithm\n","bounds = [{'name': 'Lag',                                     'type': 'discrete',      'domain': (5,6,7,8,9,10,11,12,13,14,15)},\n","          {'name': 'Learning_rate',                           'type': 'discrete',    'domain': (0.0001,0.0005,0.001,0.005,0.01,0.05)},\n","          {'name': 'dense_activation',                        'type': 'discrete',      'domain': (0,1,2)},\n","          {'name': 'output_activation',                       'type': 'discrete',      'domain': (0,1,2)},\n","         ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:31:10.049282Z","iopub.status.busy":"2023-08-01T17:31:10.048715Z","iopub.status.idle":"2023-08-01T17:31:10.061454Z","shell.execute_reply":"2023-08-01T17:31:10.060381Z","shell.execute_reply.started":"2023-08-01T17:31:10.049233Z"},"trusted":true},"outputs":[],"source":["# saving parameters of the trained models\n","def write_to_file_ATT(file_name,lag,learning_rate,denselayer_activation,output_activation,final_smape,final_rmse,final_val_RMSE,epoch):\n","    fname=\"\"+file_name +\".txt\"\n","    f1=open(fname,\"a+\")\n","    f1.write(\"lag=\")\n","    f1.write(str(lag))\n","    f1.write(\",learning_rate=\")\n","    f1.write(str(learning_rate))\n","    f1.write(\",denselayer_activation=\")\n","    f1.write(str(denselayer_activation))\n","    f1.write(\",output_activation=\")\n","    f1.write(str(output_activation))\n","    f1.write(\",final_smape=\")\n","    f1.write(str(final_smape))\n","    f1.write(\",final_rmse=\")\n","    f1.write(str(final_rmse))\n","    f1.write(\",final_val_RMSE=\")\n","    f1.write(str(final_val_RMSE))\n","    f1.write(\",epoch=\")\n","    f1.write(str(epoch))\n","    f1.write(\"\\n\")\n","    f1.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:53:02.160489Z","iopub.status.busy":"2023-08-01T17:53:02.159937Z","iopub.status.idle":"2023-08-01T17:53:02.202162Z","shell.execute_reply":"2023-08-01T17:53:02.200272Z","shell.execute_reply.started":"2023-08-01T17:53:02.160439Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["global_min_val_RMSE = math.inf\n","# the function that we want to minimize based on the beysian optimization.\n","# here we define our NN model. input parameters will be given to this function.\n","def Main(x):\n","    # first parameter is lag size \n","    lag=int(x[:,0])\n","    \n","    look_forward=7\n","    # feature indexes for each lag size, for example [1, 3, 6] means for lag size 6 the\n","    # features indexes we will use are 1,3 and 6. these indexes should be find with the\n","    # feature selection JaGen algorithm and then manually must be written here.\n","    all_features = [[4],\n","                    [1, 3, 6],\n","                    [3],\n","                    [0, 1, 8, 9, 10],\n","                    [6, 7],\n","                    [6],\n","                    [0, 3, 5, 10],\n","                    [0, 1, 3, 10],\n","                    [1],\n","                    [1, 5],\n","                    [1]\n","                   ]\n","\n","    hyper_parametrs=x[:,1:][0]\n","    all_features = all_features [lag-5]\n","    \n","    # here we need to recall HyperParameter_mapping to get model hyperparameters \n","    # and recall final_sample_creation to create samples\n","    learning_rate,denselayer_activation,output_activation=HyperParameter_mapping(hyper_parametrs)\n","    trainX,valX,testX,trainY,valY,testY,trainX_f,valX_f,testX_f=final_sample_creation(all_train,features,lag,look_forward,all_features)\n","    \n","    # initialize all metrices to zero\n","    RMSE_loss_stdev =[]\n","    SMAPE_loss_stdev =[]\n","    test_RMSE=0\n","    test_SMAPE=0\n","    RMSE_SUM = 0\n","    SMAPE_SUM = 0\n","    val_RMSE=0\n","    val_RMSE_sum=0\n","    predicted_samples = np.zeros(math.ceil(len(testX)/7) *7)\n","    \n","    global global_min_val_RMSE\n","    input2_len=int(len(trainX_f[0][0]))\n","    \n","    # performing 10 iteration at each step\n","    for j in range(10):\n","        # defining  NN layers\n","        input1 = layers.Input(shape=(1,lag,))\n","        input2 = layers.Input(shape=(1,input2_len,))\n","        \n","        multi_head1 = kl.MultiHeadAttention(key_dim=1,num_heads=lag,name='Multi-Head1')(input1,input1,input1)\n","        \n","        multi_head2 = kl.MultiHeadAttention(key_dim=1,num_heads=input2_len,name='Multi-Head2')(input2,input2,input2)                    \n","    \n","        flatt1 = kl.Flatten()(multi_head1)\n","        flatt2 = kl.Flatten()(multi_head2) \n","        concat=concatenate([flatt1,flatt2])\n","                          \n","        fully_connected1 = kl.Dense(100,activation=denselayer_activation)(concat)\n","\n","        fully_connected2 = kl.Dense(look_forward,activation=output_activation)(fully_connected1)\n","        # create model\n","        model = Model(inputs=[input1,input2],outputs=fully_connected2)\n","        # define the optimization\n","        opt=tf.keras.optimizers.Adam(lr=learning_rate)\n","        # complile the model\n","        model.compile(loss=\"mse\",optimizer=opt,metrics=[\"mse\"])\n","        # define count variable to perform early stopping method\n","        count=0\n","        # min_RMSE variable is for saving minimum validation RMSE because of controlling early stopping\n","        min_RMSE=0\n","        # here manually we perform a loop to run the model 500 times (epoch size =500)\n","        for k in range(500):\n","            history=model.fit([trainX,trainX_f],trainY,\n","                verbose=0,\n","                batch_size=1,\n","                )\n","            count+=1\n","           \n","            results = model.predict([valX,valX_f],batch_size=16, verbose=0)\n","            results = results.astype('int64')\n","            results = results.round()\n","            val_RMSE = math.sqrt(mean_squared_error(valY, results[:]))\n","            \n","            if k==0:\n","                min_RMSE=val_RMSE\n","                results = model.predict([testX,testX_f],batch_size=16, verbose=0)\n","                results = results.astype('int64')\n","                results = results.round()\n","                # we want predict 7 points at each step. but our window moving step is 1.\n","                # thus we can predict all and then pick every 7 samples to calculate Metrics on test.\n","                r_y=results[0: : 7]\n","                t_y=testY[0: : 7]\n","                test_RMSE = math.sqrt(mean_squared_error(t_y, r_y[:]))\n","                test_SMAPE = smape(t_y, r_y[:])\n","            if k>0 and val_RMSE<=min_RMSE:\n","                # if new val_RMSE finde, then put count to zero\n","                count=0\n","                min_RMSE=val_RMSE\n","                results = model.predict([testX,testX_f],batch_size=16, verbose=0)\n","                results = results.astype('int64')\n","                results = results.round()\n","                r_y=results[0: : 7]\n","                t_y=testY[0: : 7]\n","                test_RMSE = math.sqrt(mean_squared_error(t_y, r_y[:]))\n","                test_SMAPE = smape(t_y, r_y[:])\n","            # if after 50 epochs val_RMSE whouldn't improved, then break the loop.    \n","            if count>50:\n","                break\n","        # saving predicted samples \n","        predicted_samples += r_y.ravel()        \n","        # saving RMSE and SMAPE of each iteration for calculating standard deviation and final loss\n","        RMSE_SUM += test_RMSE\n","        RMSE_loss_stdev.append(test_RMSE)\n","        SMAPE_SUM += test_SMAPE\n","        SMAPE_loss_stdev.append(test_SMAPE)\n","        val_RMSE_sum +=min_RMSE\n","        K.clear_session()\n","        gc.collect()\n","        model=None\n","        del history\n","    if math.isnan(min_RMSE) or SMAPE_SUM==0:\n","        final_smape=math.inf\n","        final_rmse=math.inf\n","        final_val_RMSE=math.inf\n","    else:\n","        final_smape = SMAPE_SUM/10\n","        final_rmse = RMSE_SUM/10\n","        final_val_RMSE=val_RMSE_sum/10\n","    \n","    print(\"\\n\\n\\n Finished \\n\\n\\n\")\n","    print(\"SMAPE:\\t{0} \\t RMSE:\\t{1}\".format(final_smape, final_rmse))\n","    print(\"val_RMSE:\\t{0}\".format(final_val_RMSE))\n","    # saving all parameters and metrics in file.\n","    file_name=\"US_att_feature_params\"\n","    write_to_file_ATT(file_name,lag,learning_rate,denselayer_activation,output_activation,final_smape,final_rmse,final_val_RMSE,k)\n","    if final_val_RMSE<=global_min_val_RMSE:\n","        global_min_val_RMSE = final_val_RMSE\n","        # writing the prediction points in a txt file.\n","        f1=open(\"outputs_att_US_feature.txt\",\"w\")\n","        x = predicted_samples.ravel()\n","        x=x/10\n","        for i in x:\n","            f1.write(str(i))\n","            f1.write(\"\\n\") \n","    # calculating STD and printing all loss values.\n","    print(RMSE_loss_stdev)\n","    print(statistics.stdev(RMSE_loss_stdev))\n","    print(SMAPE_loss_stdev)\n","    print(statistics.stdev(SMAPE_loss_stdev))\n","    return final_val_RMSE "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-01T17:53:02.309334Z","iopub.status.busy":"2023-08-01T17:53:02.307798Z","iopub.status.idle":"2023-08-01T17:54:57.180881Z","shell.execute_reply":"2023-08-01T17:54:57.178284Z","shell.execute_reply.started":"2023-08-01T17:53:02.309224Z"},"trusted":true},"outputs":[],"source":["opt_us = GPyOpt.methods.BayesianOptimization(f=Main, domain=bounds)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# running bayesian optimization for 50 times.\n","opt_us.run_optimization(max_iter=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"optimized loss: {0}\".format(opt_us.fx_opt))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# best parameters\n","opt_us.x_opt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"\"\"\n","Optimized Parameters:\n","\\t{0}:\\t{1}\n","\\t{2}:\\t{3}\n","\\t{4}:\\t{5}\n","\\t{6}:\\t{7}\n","\"\"\".format(bounds[0][\"name\"],opt_us.x_opt[0],\n","           bounds[1][\"name\"],opt_us.x_opt[1],\n","           bounds[2][\"name\"],opt_us.x_opt[2],\n","           bounds[3][\"name\"],opt_us.x_opt[3],\n","           ))\n","print(\"optimized loss: {0}\".format(opt_us.fx_opt))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
